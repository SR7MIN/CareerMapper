import json
import jsonpath
import requests
from bs4 import BeautifulSoup

def get_computer_science_info():
    """格式化爬取计算机科学与技术专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/172/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("computer science.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_finance_info():
    """格式化爬取金融工程专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/9/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("finance.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()    
def get_software_engineering_info():
    """格式化爬取软件工程专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/173/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("software engineering.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()        
def get_archaeology_info():
    """格式化爬取考古学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/114/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("archaeology.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_geology_info():
    """格式化爬取地质学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/134/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("geology.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_atmospheric_science_info():
    """格式化爬取大气科学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/128/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("atmospheric science.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_politics_info():
    """格式化爬取政治学与行政学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/15/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("politics.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_news_info():
    """格式化爬取新闻学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/107/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("news.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_law_info():
    """格式化爬取法学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/14/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("law.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_society_info():
    """格式化爬取社会学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/18/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("society.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_chinese_info():
    """格式化爬取汉语言文学学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/40/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("chinese.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_education_info():
    """格式化爬取教育学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/27/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("education.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close() 
def get_human_info():
    """格式化爬取人类学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/1110/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("human.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_psychology_info():
    """格式化爬取心理学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/140/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("psychology.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_translate_info():
    """格式化爬取翻译学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/105/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("translate.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_electronics_info():
    """格式化爬取电子信息工程专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/165/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("electronics.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_biology_info():
    """格式化爬取生物科学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/136/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("biology.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_chemistry_info():
    """格式化爬取化学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/121/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("chemistry(化学).txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_material_info():
    """格式化爬取材料科学与工程专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/155/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("material.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_machine_info():
    """格式化爬取机械设计制造与自动化专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/147/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("machine(机械设计制造与自动化).txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_physics_info():
    """格式化爬取物理学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/118/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("physics.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_math_info():
    """格式化爬取数学与应用数学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/116/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("math(数学与应用数学).txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
def get_statistics_info():
    """格式化爬取统计学专业就业数据
    
    写入记事本的数据结构如下：（在读取数据时可直接参考这个结构来遍历读取）
    第一行：就业领域划分1，相邻两个就业领域以','分割，在读取数据时若不方便可在源码中将其改为空格
    第二行：对应领域划分1的所有占比，每一个数据的迭代下标与每一个领域一一对应
    第三行-第八行：就业领域划分2，每一行为一个就业领域的划分，即一个大就业领域中的各个分支综合
    第九行：对应第三到八行的每个就业领域的划分之和，以逗号相隔
    第十行：三个不同年份
    第十一行：对应第十行中三个年份的专业就业率"""
    addr='https://static-data.gaokao.cn/www/2.0/special/142/pc_special_detail.json'
    headers={"user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"}
    response=requests.get(addr,headers=headers)
    print(response)
    html_str=response.content.decode()
    jsonobj=json.loads(html_str)
    file=open("statistics.txt","w")
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].name')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.1[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].area')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.2[*].rate')))
    file.write('\n')
    file.write('\n'.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_job')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].detail_pos')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobdetail.3[*].rate')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].year')))
    file.write('\n')
    file.write(','.join(jsonpath.jsonpath(jsonobj,'$.data.jobrate[*].rate')))
    file.write('\n')
    file.close()
get_computer_science_info()
get_finance_info()
get_software_engineering_info()
get_archaeology_info()
get_geology_info()
get_atmospheric_science_info()
get_politics_info()
get_news_info()
get_law_info()
get_society_info()
get_chinese_info()
get_education_info()
get_human_info()
get_psychology_info()
get_translate_info()
get_electronics_info()
get_biology_info()
get_chemistry_info()
get_material_info()
get_machine_info()
get_physics_info()
get_math_info()
get_statistics_info()

#做了好多无用功QAQ
